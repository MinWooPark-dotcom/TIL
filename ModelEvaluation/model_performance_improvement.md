# 모델 성능 개선 방법

## SMOTE와 같은 오버샘플링 기법

- **설명**:  
  불균형한 데이터셋에서 **소수 클래스의 데이터를 인위적으로 생성**하여 학습 데이터를 균형 있게 만드는 기법입니다.  
  대표적인 방법인 **SMOTE(Synthetic Minority Over-sampling Technique)**는 기존 소수 클래스 데이터를 기반으로 **새로운 가상 데이터를 생성**합니다.

- **적합한 상황**:  
  **소수 클래스의 비율이 너무 낮아** 모델이 해당 클래스를 제대로 학습하지 못할 때 유용합니다. 특히 **분류 문제**에서 자주 사용됩니다.

- **예시**:  
  스팸 메일 분류 문제에서 스팸(소수 클래스) 데이터가 부족할 경우,  
  SMOTE를 사용해 스팸 데이터를 증강하여 학습 시 모델이 스팸도 잘 분류하도록 만듭니다.
